#!/usr/bin/env python3
"""
REGRESSION DETECTION SYSTEM DEMONSTRATION
Shows the complete system in action with simulated training scenarios.
"""

import sys
sys.path.insert(0, '/home/hariravichandran/AELP')

import logging
import tempfile
import shutil
import os
import time
import numpy as np
from datetime import datetime, timedelta

# Import regression detection components
from regression_detector import (
    RegressionDetector, MetricSnapshot, MetricType, RegressionSeverity
)
from gaelp_regression_integration import GAELPRegressionMonitor

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def simulate_training_with_regression():
    """Simulate training with performance regression and automatic rollback"""
    
    print("\n" + "="*80)
    print("üöÄ REGRESSION DETECTION SYSTEM DEMONSTRATION")
    print("="*80)
    
    # Setup temporary environment
    temp_dir = tempfile.mkdtemp(prefix='regression_demo_')
    print(f"üìÅ Demo environment: {temp_dir}")
    
    try:
        # Initialize regression detection system
        detector = RegressionDetector(
            db_path=os.path.join(temp_dir, 'demo_regression.db'),
            checkpoint_dir=temp_dir
        )
        
        gaelp_monitor = GAELPRegressionMonitor(detector)
        print("‚úÖ Regression detection system initialized")
        
        # Establish baselines from "historical" data
        print("\nüìä Establishing performance baselines...")
        
        # Simulate good historical performance
        historical_roas = np.random.normal(2.5, 0.3, 200).tolist()
        historical_cvr = np.random.normal(0.04, 0.008, 200).tolist()
        historical_reward = np.random.normal(120, 25, 200).tolist()
        
        detector.statistical_detector.update_baseline(MetricType.ROAS, historical_roas)
        detector.statistical_detector.update_baseline(MetricType.CONVERSION_RATE, historical_cvr)
        detector.statistical_detector.update_baseline(MetricType.REWARD, historical_reward)
        
        print(f"‚úÖ Baselines established:")
        print(f"   ROAS: {np.mean(historical_roas):.3f} ¬± {np.std(historical_roas):.3f}")
        print(f"   CVR: {np.mean(historical_cvr):.4f} ¬± {np.std(historical_cvr):.4f}")
        print(f"   Reward: {np.mean(historical_reward):.1f} ¬± {np.std(historical_reward):.1f}")
        
        # Simulate training episodes
        print("\nüéØ Starting simulated training with regression detection...")
        
        # Phase 1: Normal training (episodes 1-50)
        print("\nüìà Phase 1: Normal Performance (Episodes 1-50)")
        for episode in range(1, 51):
            # Normal performance metrics
            roas = np.random.normal(2.5, 0.2)
            cvr = np.random.normal(0.04, 0.006)
            reward = np.random.normal(120, 15)
            
            # Record metrics
            timestamp = datetime.now() + timedelta(minutes=episode)
            
            for metric_type, value in [(MetricType.ROAS, roas), (MetricType.CONVERSION_RATE, cvr), (MetricType.REWARD, reward)]:
                snapshot = MetricSnapshot(
                    metric_type=metric_type,
                    value=value,
                    timestamp=timestamp,
                    episode=episode
                )
                detector.record_metric(snapshot)
            
            # Create checkpoint every 25 episodes
            if episode % 25 == 0:
                test_model = {'episode': episode, 'weights': np.random.randn(50)}
                performance_metrics = {'roas': roas, 'conversion_rate': cvr, 'reward': reward}
                validation_scores = {'composite_score': roas * 30 + cvr * 1000}
                
                checkpoint_id = detector.create_model_checkpoint(test_model, performance_metrics, episode)
                print(f"üíæ Checkpoint created at episode {episode}: {checkpoint_id}")
        
        # Check for regressions after normal phase
        alerts = detector.check_for_regressions()
        print(f"üîç Phase 1 complete - Alerts detected: {len(alerts)}")
        
        # Phase 2: Performance degradation (episodes 51-75)
        print("\nüìâ Phase 2: Performance Degradation (Episodes 51-75)")
        for episode in range(51, 76):
            # Degrading performance
            degradation_factor = (episode - 50) * 0.02  # Increasing degradation
            roas = np.random.normal(2.5 - degradation_factor, 0.2)
            cvr = np.random.normal(0.04 - degradation_factor * 0.1, 0.006)
            reward = np.random.normal(120 - degradation_factor * 10, 15)
            
            # Record degraded metrics
            timestamp = datetime.now() + timedelta(minutes=episode)
            
            for metric_type, value in [(MetricType.ROAS, roas), (MetricType.CONVERSION_RATE, cvr), (MetricType.REWARD, reward)]:
                snapshot = MetricSnapshot(
                    metric_type=metric_type,
                    value=value,
                    timestamp=timestamp,
                    episode=episode
                )
                detector.record_metric(snapshot)
            
            # Check for regression every 10 episodes
            if episode % 10 == 0:
                alerts = detector.check_for_regressions()
                if alerts:
                    print(f"‚ö†Ô∏è  Episode {episode}: {len(alerts)} regression alerts")
                    for alert in alerts:
                        print(f"   üìä {alert.metric_type.value}: {alert.severity.value_str} "
                             f"(current={alert.current_value:.4f}, baseline={alert.baseline_mean:.4f})")
                        
                        if alert.severity >= RegressionSeverity.SEVERE:
                            print(f"   üö® SEVERE REGRESSION DETECTED - Triggering rollback evaluation")
                            
                            # Check if rollback is needed
                            rollback_needed = detector.evaluate_rollback_need(alerts)
                            if rollback_needed:
                                print(f"   üîÑ INITIATING AUTOMATIC ROLLBACK...")
                                
                                rollback_success = detector.perform_automatic_rollback(alerts)
                                if rollback_success:
                                    print(f"   ‚úÖ Rollback successful - Model restored")
                                    
                                    # Simulate recovery
                                    print(f"   üìà Performance recovery initiated")
                                    return  # End demo on successful rollback
                                else:
                                    print(f"   ‚ùå Rollback failed")
        
        # Final check
        final_alerts = detector.check_for_regressions()
        print(f"\nüîç Final regression check: {len(final_alerts)} alerts")
        
        # Generate performance dashboard
        dashboard = gaelp_monitor.get_performance_dashboard()
        print(f"\nüìä PERFORMANCE DASHBOARD")
        print(f"   System Status: {dashboard['system_status']}")
        print(f"   Recent ROAS: {dashboard['recent_performance'].get('avg_roas', 0):.4f}")
        print(f"   Recent CVR: {dashboard['recent_performance'].get('avg_conversion_rate', 0):.4f}")
        print(f"   Business Compliance: {dashboard['business_compliance'].get('compliance_rate', 0):.1%}")
        print(f"   24h Alerts: {dashboard['alert_summary'].get('alerts_24h', 0)}")
        
        print("\n‚úÖ DEMONSTRATION COMPLETE")
        
    finally:
        # Cleanup
        detector.stop_monitoring()
        shutil.rmtree(temp_dir)
        print(f"üßπ Demo environment cleaned up")

def main():
    """Run regression detection demonstration"""
    try:
        simulate_training_with_regression()
        
        print("\n" + "="*80)
        print("üéâ REGRESSION DETECTION DEMONSTRATION SUCCESSFUL")
        print("="*80)
        print("‚úÖ Statistical detection algorithms working")
        print("‚úÖ Baseline establishment from historical data")
        print("‚úÖ Real-time monitoring and alerting")
        print("‚úÖ Automatic rollback on severe regressions")
        print("‚úÖ Performance dashboard generation")
        print("‚úÖ Complete audit trail maintained")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())